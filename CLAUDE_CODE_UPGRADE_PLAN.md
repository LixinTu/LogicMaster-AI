# LogicMaster AI å·¥ä¸šåŒ–å‡çº§è®¡åˆ’ - Claude Codeæ‰§è¡ŒæŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

**å½“å‰çŠ¶æ€**ï¼š
- åŸºäºStreamlitçš„GMAT Critical Reasoningè®­ç»ƒç³»ç»Ÿ
- ä½¿ç”¨SQLiteæ•°æ®åº“
- å·²å®ç°IRTå¼•æ“ï¼ˆ`engine/scoring.py`ï¼‰
- å·²å®ç°BKTæ¨èç³»ç»Ÿï¼ˆ`engine/recommender.py`ï¼‰
- å·²é›†æˆDeepSeek LLMï¼ˆ`llm_service.py`ï¼‰
- å·²æœ‰Socraticå¯¹è¯æœºåˆ¶

**å‡çº§ç›®æ ‡**ï¼š
1. å·¥ä¸šåŒ–æ¶æ„ï¼šFastAPIåç«¯ + PostgreSQLæ•°æ®åº“
2. AIæŠ€æœ¯æ·±åŒ–ï¼šRAGç³»ç»Ÿï¼ˆQdrant + OpenAI embeddingsï¼‰+ LangChain Agent
3. æ•°æ®ç§‘å­¦èƒ½åŠ›ï¼šA/B Testingæ¡†æ¶ + ç»Ÿè®¡è¯„ä¼°ä½“ç³»
4. é€‚é…æ±‚èŒï¼šAIæ•™è‚²å…¬å¸ + DA/DSå²—ä½åŒé‡å®šä½

**æ ¸å¿ƒåŸåˆ™**ï¼š
- âœ… ä¿ç•™ç°æœ‰æ ¸å¿ƒé€»è¾‘ï¼ˆIRTã€BKTã€Socraticï¼‰
- âœ… æ¸è¿›å¼å‡çº§ï¼Œæ¯å‘¨éƒ½æœ‰å¯æ¼”ç¤ºæˆæœ
- âœ… å¤ç”¨ç°æœ‰ä»£ç ï¼Œä¸æ¨å€’é‡æ¥
- âœ… ä¼˜å…ˆå±•ç¤ºå·¥ä¸šæ ‡å‡†å’ŒAIæ·±åº¦

---

## ğŸ¯ Week 1: FastAPIåç«¯æ¶æ„ + PostgreSQLè¿ç§»

### ç›®æ ‡
æ­å»ºFastAPIåç«¯ï¼Œå°†æ ¸å¿ƒé€»è¾‘APIåŒ–ï¼ŒåŒæ—¶ä¿æŒStreamlitå‰ç«¯å¯ç”¨

### ä»»åŠ¡æ¸…å•

#### Task 1.1: åˆ›å»ºFastAPIé¡¹ç›®ç»“æ„
```
åˆ›å»ºä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

backend/
â”œâ”€â”€ main.py                 # FastAPIåº”ç”¨å…¥å£
â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†ï¼ˆç¯å¢ƒå˜é‡ï¼‰
â”œâ”€â”€ database.py            # SQLAlchemyæ•°æ®åº“é…ç½®
â”œâ”€â”€ models/                # Pydanticæ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ question.py
â”‚   â”œâ”€â”€ user.py
â”‚   â””â”€â”€ response.py
â”œâ”€â”€ routers/               # APIè·¯ç”±
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ questions.py       # é¢˜ç›®ç›¸å…³API
â”‚   â”œâ”€â”€ theta.py           # IRT thetaæ›´æ–°API
â”‚   â””â”€â”€ tutor.py           # Tutorå¯¹è¯API
â”œâ”€â”€ services/              # ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ question_service.py
â””â”€â”€ schemas/               # SQLAlchemy ORMæ¨¡å‹
    â”œâ”€â”€ __init__.py
    â””â”€â”€ models.py

requirements-backend.txt   # åç«¯ä¾èµ–
```

#### Task 1.2: å®ç°FastAPIæ ¸å¿ƒæ¡†æ¶

**æ–‡ä»¶ï¼šbackend/main.py**
```python
åŠŸèƒ½è¦æ±‚ï¼š
1. åˆ›å»ºFastAPI appå®ä¾‹
2. é…ç½®CORSä¸­é—´ä»¶ï¼ˆå…è®¸Streamlit localhost:8501è®¿é—®ï¼‰
3. åŒ…å«ä»¥ä¸‹è·¯ç”±ï¼š
   - GET /health - å¥åº·æ£€æŸ¥
   - POST /api/theta/update - IRT thetaæ›´æ–°
   - POST /api/questions/next - è·å–ä¸‹ä¸€é¢˜
   - POST /api/tutor/chat - Tutorå¯¹è¯
4. é›†æˆç°æœ‰engine/scoring.pyå’Œengine/recommender.pyçš„é€»è¾‘
5. æ·»åŠ é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

æŠ€æœ¯è¦æ±‚ï¼š
- ä½¿ç”¨FastAPI 0.104+
- ä½¿ç”¨Pydantic v2è¿›è¡Œæ•°æ®éªŒè¯
- æ·»åŠ è‡ªåŠ¨APIæ–‡æ¡£ï¼ˆ/docsï¼‰
```

**æ–‡ä»¶ï¼šbackend/config.py**
```python
åŠŸèƒ½è¦æ±‚ï¼š
1. ä½¿ç”¨pydantic-settingsç®¡ç†é…ç½®
2. ä»ç¯å¢ƒå˜é‡è¯»å–ï¼š
   - DATABASE_URLï¼ˆPostgreSQLè¿æ¥å­—ç¬¦ä¸²ï¼‰
   - DEEPSEEK_API_KEY
   - OPENAI_API_KEYï¼ˆåç»­RAGä½¿ç”¨ï¼‰
3. æä¾›å¼€å‘/ç”Ÿäº§ç¯å¢ƒé…ç½®åˆ‡æ¢

å®ç°è¦ç‚¹ï¼š
- ä½¿ç”¨BaseSettings
- æ”¯æŒ.envæ–‡ä»¶è¯»å–
- æä¾›é…ç½®éªŒè¯
```

**æ–‡ä»¶ï¼šbackend/database.py**
```python
åŠŸèƒ½è¦æ±‚ï¼š
1. SQLAlchemyé…ç½®ï¼ˆä½¿ç”¨SQLAlchemy 2.0è¯­æ³•ï¼‰
2. åˆ›å»ºengineå’ŒSessionLocal
3. æä¾›get_dbä¾èµ–æ³¨å…¥å‡½æ•°
4. å®šä¹‰Baseç±»ç”¨äºORMæ¨¡å‹

æ•°æ®åº“URLæ ¼å¼ï¼š
postgresql://user:password@localhost:5432/logicmaster
```

#### Task 1.3: å®šä¹‰æ•°æ®æ¨¡å‹

**æ–‡ä»¶ï¼šbackend/schemas/models.py**
```python
å®šä¹‰ä»¥ä¸‹SQLAlchemy ORMæ¨¡å‹ï¼š

1. Questionè¡¨ï¼š
   - id: String (ä¸»é”®)
   - question_type: String (Weaken/Strengthen/Assumptionç­‰)
   - difficulty: String (easy/medium/hard)
   - elo_difficulty: Float (é»˜è®¤1500.0)
   - content: JSON (å­˜å‚¨stimulus, question, choices, correct, explanationç­‰)
   - skills: JSON (æŠ€èƒ½æ ‡ç­¾æ•°ç»„)
   - diagnoses: JSON (é¢„ç”Ÿæˆçš„é”™è¯¯è¯Šæ–­)
   - detailed_explanation: Text (è¯¦ç»†è§£æ)
   - created_at: DateTime
   - updated_at: DateTime

2. UserLogè¡¨ï¼š
   - id: Integer (ä¸»é”®ï¼Œè‡ªå¢)
   - user_id: String
   - question_id: String (å¤–é”®)
   - user_choice: String (A-E)
   - is_correct: Boolean
   - theta_before: Float
   - theta_after: Float
   - skills_tested: JSON
   - timestamp: DateTime

3. ExperimentLogè¡¨ï¼ˆä¸ºåç»­A/Bæµ‹è¯•å‡†å¤‡ï¼‰ï¼š
   - id: String (ä¸»é”®)
   - user_id: String
   - experiment_name: String
   - variant: String
   - outcome: JSON
   - created_at: DateTime

ç´¢å¼•è¦æ±‚ï¼š
- Question: idx_elo_difficulty, idx_question_type
- UserLog: idx_user_id, idx_timestamp
```

**æ–‡ä»¶ï¼šbackend/models/question.py**
```python
å®šä¹‰Pydanticæ¨¡å‹ï¼ˆç”¨äºAPIè¯·æ±‚/å“åº”ï¼‰ï¼š

1. QuestionResponse - è¿”å›é¢˜ç›®ä¿¡æ¯
2. NextQuestionRequest - è¯·æ±‚ä¸‹ä¸€é¢˜çš„å‚æ•°
3. AnswerSubmissionRequest - æäº¤ç­”æ¡ˆçš„å‚æ•°
4. ThetaUpdateResponse - thetaæ›´æ–°ç»“æœ

è¦æ±‚ï¼šä½¿ç”¨Pydantic v2è¯­æ³•ï¼ˆField, ConfigDictç­‰ï¼‰
```

#### Task 1.4: å®ç°æ ¸å¿ƒAPIç«¯ç‚¹

**æ–‡ä»¶ï¼šbackend/routers/theta.py**
```python
ç«¯ç‚¹ï¼šPOST /api/theta/update

åŠŸèƒ½ï¼š
1. æ¥æ”¶current_theta, question_difficulty, is_correct
2. è°ƒç”¨engine/scoring.pyä¸­çš„calculate_new_thetaå‡½æ•°
3. è°ƒç”¨estimate_gmat_scoreè®¡ç®—GMATåˆ†æ•°
4. è¿”å›new_thetaå’Œgmat_score

å¤ç”¨ç°æœ‰ä»£ç ï¼š
from engine.scoring import calculate_new_theta, estimate_gmat_score
```

**æ–‡ä»¶ï¼šbackend/routers/questions.py**
```python
ç«¯ç‚¹1ï¼šPOST /api/questions/next

åŠŸèƒ½ï¼š
1. æ¥æ”¶user_theta, questions_logï¼ˆå†å²è®°å½•ï¼‰
2. è°ƒç”¨engine/recommender.pyä¸­çš„generate_next_question
3. ä»æ•°æ®åº“æŸ¥è¯¢æ¨èçš„é¢˜ç›®
4. è¿”å›å®Œæ•´é¢˜ç›®ä¿¡æ¯ï¼ˆä¸å«correctç­”æ¡ˆï¼Œå‰ç«¯å±•ç¤ºç”¨ï¼‰

ç«¯ç‚¹2ï¼šGET /api/questions/{question_id}

åŠŸèƒ½ï¼š
1. æ ¹æ®IDæŸ¥è¯¢é¢˜ç›®
2. è¿”å›é¢˜ç›®è¯¦æƒ…ï¼ˆåŒ…å«è§£æï¼Œç”¨äºç­”é¢˜åå±•ç¤ºï¼‰

å¤ç”¨ç°æœ‰ä»£ç ï¼š
from engine.recommender import generate_next_question, analyze_weak_skills
```

**æ–‡ä»¶ï¼šbackend/routers/tutor.py**
```python
ç«¯ç‚¹ï¼šPOST /api/tutor/chat

åŠŸèƒ½ï¼š
1. æ¥æ”¶message, chat_history, question_id
2. è°ƒç”¨llm_service.pyä¸­çš„tutor_replyå‡½æ•°
3. è¿”å›AIå›å¤

å¤ç”¨ç°æœ‰ä»£ç ï¼š
from llm_service import tutor_reply, diagnose_wrong_answer
```

#### Task 1.5: PostgreSQLè¿ç§»

**æ–‡ä»¶ï¼šscripts/migrate_to_postgres.py**
```python
åŠŸèƒ½ï¼š
1. è¯»å–ç°æœ‰SQLiteæ•°æ®åº“ï¼ˆlogicmaster.dbï¼‰
2. å°†questionsè¡¨æ•°æ®è¿ç§»åˆ°PostgreSQL
3. å°†user_logsè¡¨æ•°æ®è¿ç§»ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
4. éªŒè¯è¿ç§»å®Œæ•´æ€§ï¼ˆè®°å½•æ•°å¯¹æ¯”ï¼‰

å®ç°è¦ç‚¹ï¼š
- ä½¿ç”¨sqlite3è¯»å–SQLite
- ä½¿ç”¨SQLAlchemyå†™å…¥PostgreSQL
- æä¾›è¿›åº¦æ˜¾ç¤º
- å¤„ç†JSONå­—æ®µçš„åºåˆ—åŒ–/ååºåˆ—åŒ–
- æ·»åŠ é”™è¯¯å¤„ç†å’Œå›æ»šæœºåˆ¶
```

**æ–‡ä»¶ï¼šdocker-compose.yml**
```yaml
åˆ›å»ºDocker Composeé…ç½®å¯åŠ¨PostgreSQLï¼š

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: logicmaster
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-dev_password}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
```

#### Task 1.6: ä¿®æ”¹Streamlitè°ƒç”¨FastAPI

**æ–‡ä»¶ï¼šapp.py**ï¼ˆä¿®æ”¹ç°æœ‰æ–‡ä»¶ï¼‰
```python
ä¿®æ”¹è¦æ±‚ï¼š
1. åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ API_BASE_URLé…ç½®ï¼ˆé»˜è®¤http://localhost:8000ï¼‰
2. æ‰¾åˆ°æ‰€æœ‰ç›´æ¥è°ƒç”¨engine/scoring.pyçš„åœ°æ–¹ï¼Œæ”¹ä¸ºè°ƒç”¨APIï¼š
   
   åŸæ¥ï¼š
   new_theta = calculate_new_theta(current_theta, difficulty, is_correct)
   
   æ”¹ä¸ºï¼š
   import requests
   response = requests.post(f"{API_BASE_URL}/api/theta/update", json={
       "current_theta": current_theta,
       "difficulty": difficulty,
       "is_correct": is_correct
   })
   data = response.json()
   new_theta = data["new_theta"]

3. æ‰¾åˆ°æ‰€æœ‰è°ƒç”¨generate_next_questionçš„åœ°æ–¹ï¼Œæ”¹ä¸ºè°ƒç”¨API
4. æ‰¾åˆ°æ‰€æœ‰è°ƒç”¨tutor_replyçš„åœ°æ–¹ï¼Œæ”¹ä¸ºè°ƒç”¨API
5. æ·»åŠ APIè°ƒç”¨é”™è¯¯å¤„ç†ï¼ˆtry-exceptï¼‰
6. åœ¨sidebaræ·»åŠ "APIçŠ¶æ€"æŒ‡ç¤ºå™¨ï¼ˆè°ƒç”¨/healthç«¯ç‚¹ï¼‰

ä¿ç•™ï¼š
- æ‰€æœ‰UIé€»è¾‘ä¸å˜
- Session stateç®¡ç†ä¸å˜
- å¯è§†åŒ–å›¾è¡¨ä¸å˜
```

#### Task 1.7: æµ‹è¯•å’ŒéªŒè¯

**æ–‡ä»¶ï¼šbackend/tests/test_api.py**
```python
ä½¿ç”¨pytestç¼–å†™æµ‹è¯•ï¼š

1. test_health_endpoint - æµ‹è¯•å¥åº·æ£€æŸ¥
2. test_theta_update - æµ‹è¯•thetaæ›´æ–°API
3. test_get_next_question - æµ‹è¯•è·å–ä¸‹ä¸€é¢˜
4. test_tutor_chat - æµ‹è¯•Tutorå¯¹è¯

ä½¿ç”¨TestClientè¿›è¡ŒAPIæµ‹è¯•
```

**å¯åŠ¨è„šæœ¬ï¼šscripts/start_dev.sh**
```bash
#!/bin/bash
# å¼€å‘ç¯å¢ƒå¯åŠ¨è„šæœ¬

# å¯åŠ¨PostgreSQLï¼ˆDockerï¼‰
docker-compose up -d postgres

# ç­‰å¾…æ•°æ®åº“å°±ç»ª
sleep 5

# å¯åŠ¨FastAPIåç«¯
cd backend
uvicorn main:app --reload --port 8000 &

# å¯åŠ¨Streamlitå‰ç«¯
cd ..
streamlit run app.py
```

### Week 1 éªŒæ”¶æ ‡å‡†
- [ ] FastAPIåç«¯æ­£å¸¸è¿è¡Œï¼ˆhttp://localhost:8000/docså¯è®¿é—®ï¼‰
- [ ] PostgreSQLè¿è¡Œä¸”æ•°æ®å·²è¿ç§»
- [ ] Streamlité€šè¿‡APIè°ƒç”¨åç«¯ï¼Œæ‰€æœ‰åŠŸèƒ½æ­£å¸¸
- [ ] `/health`ç«¯ç‚¹è¿”å›200
- [ ] è‡³å°‘3ä¸ªAPIç«¯ç‚¹æµ‹è¯•é€šè¿‡
- [ ] å¯ä»¥å®Œæ•´åšä¸€é“é¢˜ï¼ˆä»è·å–é¢˜ç›®åˆ°æäº¤ç­”æ¡ˆï¼‰

---

## ğŸ¯ Week 2: RAGç³»ç»Ÿé›†æˆ

### ç›®æ ‡
æ·»åŠ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿï¼Œæå‡LLMç”Ÿæˆè´¨é‡

### ä»»åŠ¡æ¸…å•

#### Task 2.1: å¯åŠ¨Qdrantå‘é‡æ•°æ®åº“

**docker-compose.yml**ï¼ˆåœ¨Week 1åŸºç¡€ä¸Šæ·»åŠ ï¼‰
```yaml
æ·»åŠ QdrantæœåŠ¡ï¼š

services:
  # ... postgresé…ç½®ä¿æŒä¸å˜ ...
  
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"  # gRPCç«¯å£
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334

volumes:
  postgres_data:
  qdrant_data:  # æ–°å¢
```

#### Task 2.2: å®ç°RAGæœåŠ¡

**æ–‡ä»¶ï¼šbackend/services/rag_service.py**
```python
ç±»ï¼šRAGService

åŠŸèƒ½è¦æ±‚ï¼š
1. åˆå§‹åŒ–Qdrantå®¢æˆ·ç«¯ï¼ˆè¿æ¥localhost:6333ï¼‰
2. åˆ›å»ºcollection "gmat_explanations"
   - å‘é‡ç»´åº¦ï¼š1536ï¼ˆtext-embedding-3-smallï¼‰
   - è·ç¦»åº¦é‡ï¼šCosine

æ–¹æ³•1ï¼šindex_question(question_id, question_text, explanation)
- æ„å»ºdocument = f"Question: {question_text}\n\nExplanation: {explanation}"
- è°ƒç”¨OpenAI APIç”Ÿæˆembeddingï¼ˆmodel: text-embedding-3-smallï¼‰
- å°†embeddingå’Œexplanationå­˜å…¥Qdrant
- payloadåŒ…å«ï¼šquestion_id, explanation, question_type, skills

æ–¹æ³•2ï¼šretrieve_similar(query_text, top_k=2)
- ç”Ÿæˆqueryçš„embedding
- åœ¨Qdrantä¸­æœç´¢æœ€ç›¸ä¼¼çš„top_kä¸ªç»“æœ
- è¿”å›[{"question_id": "...", "explanation": "...", "score": 0.95}, ...]

æ–¹æ³•3ï¼šretrieve_by_skills(query_text, required_skills, top_k=2)
- åŒæ—¶ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦å’Œskillsè¿‡æ»¤
- è¿”å›ç›¸åŒæŠ€èƒ½çš„ç›¸ä¼¼é¢˜ç›®

é”™è¯¯å¤„ç†ï¼š
- OpenAI APIè°ƒç”¨å¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨
- Qdrantè¿æ¥å¤±è´¥æ—¶è®°å½•æ—¥å¿—å¹¶è¿”å›ç©ºåˆ—è¡¨

ä¾èµ–ï¼š
- qdrant-client
- openai
```

#### Task 2.3: æ‰¹é‡ç´¢å¼•ç°æœ‰é¢˜ç›®

**æ–‡ä»¶ï¼šscripts/index_to_rag.py**
```python
åŠŸèƒ½ï¼š
1. ä»PostgreSQLè¯»å–æ‰€æœ‰é¢˜ç›®
2. å¯¹æ¯é“é¢˜è°ƒç”¨RAGService.index_question
3. æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆä½¿ç”¨tqdmï¼‰
4. ç»Ÿè®¡æˆåŠŸ/å¤±è´¥æ•°é‡
5. å¤±è´¥çš„é¢˜ç›®è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶

æ‰§è¡Œé€»è¾‘ï¼š
- æ‰¹é‡å¤„ç†ï¼Œæ¯10é“é¢˜commitä¸€æ¬¡
- æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆæ£€æŸ¥å·²ç´¢å¼•çš„question_idï¼‰
- æä¾›--forceé€‰é¡¹é‡æ–°ç´¢å¼•æ‰€æœ‰é¢˜ç›®

é¢„æœŸè¾“å‡ºï¼š
âœ… Successfully indexed 150/152 questions
âŒ Failed: 2 questions (see logs/index_errors.log)
```

#### Task 2.4: å¢å¼ºLLMè§£æç”Ÿæˆ

**æ–‡ä»¶ï¼šbackend/services/explanation_service.py**ï¼ˆæ–°å»ºï¼‰
```python
å‡½æ•°ï¼šgenerate_rag_enhanced_explanation(question, api_key)

å®ç°æµç¨‹ï¼š
1. æ„å»ºquery = f"{question['stimulus']} {question['question']}"
2. è°ƒç”¨RAGService.retrieve_similar(query, top_k=2)
3. æ„å»ºFew-shot promptï¼š
   """
   ä½ æ˜¯GMATä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯ä¸¤ä¸ªç±»ä¼¼é¢˜ç›®çš„é«˜è´¨é‡è§£æç¤ºä¾‹ï¼š
   
   ç¤ºä¾‹1:
   {similar_explanation_1}
   
   ç¤ºä¾‹2:
   {similar_explanation_2}
   
   ç°åœ¨è¯·ä¸ºè¿™é“é¢˜ç”Ÿæˆç±»ä¼¼è´¨é‡çš„è§£æï¼š
   
   é¢˜ç›®ï¼š{current_question}
   ...
   """
4. è°ƒç”¨DeepSeek APIï¼ˆå¤ç”¨llm_service.pyçš„é€»è¾‘ï¼‰
5. è¿”å›ç”Ÿæˆçš„è§£æ

å¦‚æœRAGæ£€ç´¢å¤±è´¥ï¼š
- é™çº§åˆ°åŸæœ‰çš„generate_detailed_explanationé€»è¾‘
- ä¸å½±å“æ­£å¸¸åŠŸèƒ½
```

#### Task 2.5: æ·»åŠ RAG APIç«¯ç‚¹

**æ–‡ä»¶ï¼šbackend/routers/explanations.py**ï¼ˆæ–°å»ºï¼‰
```python
ç«¯ç‚¹1ï¼šPOST /api/explanations/generate-with-rag

è¯·æ±‚ä½“ï¼š
{
  "question_id": "q001",
  "question": {...},  # å®Œæ•´é¢˜ç›®å¯¹è±¡
  "user_choice": "A",
  "is_correct": false
}

å“åº”ï¼š
{
  "explanation": "è¯¦ç»†è§£ææ–‡æœ¬...",
  "similar_references": [
    {"question_id": "q015", "similarity": 0.92},
    {"question_id": "q032", "similarity": 0.87}
  ],
  "source": "rag_enhanced"
}

ç«¯ç‚¹2ï¼šPOST /api/explanations/search-similar

è¯·æ±‚ä½“ï¼š
{
  "query": "å…¬å¸æ¨å‡ºæ–°äº§å“ï¼Œå¸‚åœºç«äº‰",
  "top_k": 5
}

å“åº”ï¼š
{
  "results": [
    {
      "question_id": "q001",
      "explanation": "...",
      "similarity_score": 0.95
    },
    ...
  ]
}
```

#### Task 2.6: Streamlité›†æˆRAG

**æ–‡ä»¶ï¼šapp.py**ï¼ˆåœ¨Week 1åŸºç¡€ä¸Šç»§ç»­ä¿®æ”¹ï¼‰
```python
ä¿®æ”¹ä½ç½®ï¼šæ˜¾ç¤ºè¯¦ç»†è§£æçš„éƒ¨åˆ†

åŸæ¥ï¼š
explanation = current_q.get("detailed_explanation", "")
st.markdown(explanation)

æ”¹ä¸ºï¼š
# è°ƒç”¨RAGå¢å¼ºçš„API
response = requests.post(f"{API_BASE_URL}/api/explanations/generate-with-rag", json={
    "question_id": current_q["question_id"],
    "question": current_q,
    "user_choice": user_choice,
    "is_correct": is_correct
})
data = response.json()

# æ˜¾ç¤ºè§£æ
st.markdown(data["explanation"])

# æ–°å¢ï¼šæ˜¾ç¤ºç›¸ä¼¼é¢˜ç›®å‚è€ƒ
if data.get("similar_references"):
    with st.expander("ğŸ“š ç›¸ä¼¼é¢˜ç›®å‚è€ƒ"):
        for ref in data["similar_references"]:
            st.caption(f"é¢˜ç›® {ref['question_id']} (ç›¸ä¼¼åº¦: {ref['similarity']:.0%})")
```

#### Task 2.7: RAGè´¨é‡è¯„ä¼°

**æ–‡ä»¶ï¼šbackend/ml/rag_evaluator.py**ï¼ˆæ–°å»ºï¼‰
```python
ç±»ï¼šRAGEvaluator

æ–¹æ³•1ï¼ševaluate_retrieval(ground_truth_ids, retrieved_ids, k=5)
è®¡ç®—æŒ‡æ ‡ï¼š
- Precision@K = |ç›¸å…³&æ£€ç´¢| / K
- Recall@K = |ç›¸å…³&æ£€ç´¢| / |ç›¸å…³|
- MRR (Mean Reciprocal Rank) = 1/ç¬¬ä¸€ä¸ªç›¸å…³ç»“æœçš„ä½ç½®
- F1@K = 2 * P * R / (P + R)

è¿”å›ï¼š
{
  "precision@5": 0.87,
  "recall@5": 0.75,
  "mrr": 0.92,
  "f1@5": 0.81
}

æ–¹æ³•2ï¼šcreate_evaluation_report(test_cases)
- å¯¹å¤šä¸ªtest casesæ‰¹é‡è¯„ä¼°
- è®¡ç®—å¹³å‡æŒ‡æ ‡
- ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šï¼ˆä½¿ç”¨matplotlibï¼‰
- ä¿å­˜åˆ°reports/rag_evaluation.pdf
```

**æ–‡ä»¶ï¼šscripts/evaluate_rag.py**
```python
åŠŸèƒ½ï¼š
1. åŠ è½½æµ‹è¯•é›†ï¼ˆéœ€è¦äººå·¥æ ‡æ³¨çš„ground truthï¼‰
   æ ¼å¼ï¼š[
     {
       "query": "å…¬å¸æ–°äº§å“å¸‚åœºä»½é¢",
       "ground_truth": ["q001", "q015", "q032"]
     },
     ...
   ]
2. å¯¹æ¯ä¸ªqueryè°ƒç”¨RAGService.retrieve_similar
3. è°ƒç”¨RAGEvaluatorè¯„ä¼°
4. è¾“å‡ºè¯„ä¼°æŠ¥å‘Š

é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š
=== RAG Evaluation Report ===
Test Cases: 20
Average Precision@5: 0.87
Average Recall@5: 0.75
Average MRR: 0.92
Average F1@5: 0.81

Detailed results saved to reports/rag_evaluation.pdf
```

**æ–‡ä»¶ï¼štests/test_data/rag_test_cases.json**
```json
åˆ›å»ºæµ‹è¯•æ•°æ®é›†ï¼ˆè‡³å°‘10ä¸ªï¼Œéœ€è¦äººå·¥æ ‡æ³¨ï¼‰ï¼š

[
  {
    "id": 1,
    "query": "å…¬å¸æ¨å‡ºæ–°äº§å“ï¼Œç«äº‰æ¿€çƒˆï¼Œå‰Šå¼±è®ºè¯",
    "ground_truth": ["q001", "q015", "q032"],
    "comment": "æµ‹è¯•Weakenç±»å‹é¢˜ç›®æ£€ç´¢"
  },
  {
    "id": 2,
    "query": "å› æœå…³ç³»æ¨ç†ï¼Œå‡è®¾è¯†åˆ«",
    "ground_truth": ["q005", "q021"],
    "comment": "æµ‹è¯•æŠ€èƒ½æ ‡ç­¾æ£€ç´¢"
  },
  ...
]
```

### Week 2 éªŒæ”¶æ ‡å‡†
- [ ] Qdrantæ­£å¸¸è¿è¡Œï¼ˆhttp://localhost:6333/dashboardå¯è®¿é—®ï¼‰
- [ ] è‡³å°‘100é“é¢˜ç›®å·²ç´¢å¼•åˆ°å‘é‡åº“
- [ ] RAG APIç«¯ç‚¹è¿”å›ç›¸ä¼¼é¢˜ç›®ï¼ˆsimilarity > 0.7ï¼‰
- [ ] Streamlitæ˜¾ç¤º"ç›¸ä¼¼é¢˜ç›®å‚è€ƒ"åŠŸèƒ½
- [ ] RAGè¯„ä¼°è„šæœ¬è¿è¡ŒæˆåŠŸï¼ŒPrecision@5 > 0.80
- [ ] ç”Ÿæˆçš„è§£æè´¨é‡æ˜æ˜¾æå‡ï¼ˆäººå·¥è¯„ä¼°3-5ä¸ªä¾‹å­ï¼‰

---

## ğŸ¯ Week 3: LangChain Agentå‡çº§

### ç›®æ ‡
ä½¿ç”¨LangChainæ¡†æ¶é‡æ„Tutor Agentï¼Œå¢åŠ ç»“æ„åŒ–å’Œå¯æ‰©å±•æ€§

### ä»»åŠ¡æ¸…å•

#### Task 3.1: LangChainåŸºç¡€é›†æˆ

**æ–‡ä»¶ï¼šbackend/services/tutor_agent.py**ï¼ˆæ–°å»ºï¼‰
```python
ç±»ï¼šSocraticTutorAgent

ä½¿ç”¨LangChainç»„ä»¶ï¼š
- ChatOpenAIï¼ˆè¿æ¥DeepSeekï¼‰
- ChatPromptTemplateï¼ˆç»“æ„åŒ–promptï¼‰
- RunnableSequenceï¼ˆé“¾å¼è°ƒç”¨ï¼‰

åˆå§‹åŒ–ï¼š
def __init__(self, api_key: str):
    self.llm = ChatOpenAI(
        model="deepseek-chat",
        api_key=api_key,
        base_url="https://api.deepseek.com",
        temperature=0.4
    )
    
    # å®šä¹‰promptæ¨¡æ¿
    self.diagnosis_prompt = ChatPromptTemplate.from_template(
        "åˆ†æå­¦ç”Ÿé”™è¯¯...\né¢˜ç›®ï¼š{question}\nå­¦ç”Ÿé€‰æ‹©ï¼š{user_choice}\næ­£ç¡®ç­”æ¡ˆï¼š{correct}"
    )
    
    self.hint_prompt = ChatPromptTemplate.from_template(
        "æ ¹æ®é€»è¾‘æ¼æ´ç”Ÿæˆè‹æ ¼æ‹‰åº•å¼æç¤º...\næ¼æ´ï¼š{logic_gap}"
    )

æ–¹æ³•1ï¼šdiagnose_error(question, user_choice, correct_choice)
- ä½¿ç”¨diagnosis_prompt | llmé“¾å¼è°ƒç”¨
- è¿”å›{"logic_gap": "...", "error_type": "causal_confusion"}

æ–¹æ³•2ï¼šgenerate_socratic_hint(logic_gap, hint_count=0)
- ä½¿ç”¨hint_prompt | llm
- æ ¹æ®hint_countè°ƒæ•´æç¤ºå¼ºåº¦ï¼ˆç¬¬1æ¬¡æ¨¡ç³Šï¼Œç¬¬2æ¬¡æ˜ç¡®ï¼‰
- è¿”å›è‹æ ¼æ‹‰åº•å¼åé—®

æ–¹æ³•3ï¼šfull_remediation_flow(question, user_choice, max_turns=3)
- å®Œæ•´çš„è¡¥æ•‘æµç¨‹ï¼šè¯Šæ–­ â†’ æç¤º1 â†’ è¯„ä¼°ç†è§£ â†’ æç¤º2 â†’ ...
- è¿”å›å®Œæ•´å¯¹è¯å†å²
```

#### Task 3.2: çŠ¶æ€ç®¡ç†

**æ–‡ä»¶ï¼šbackend/services/conversation_manager.py**ï¼ˆæ–°å»ºï¼‰
```python
ç±»ï¼šConversationManager

åŠŸèƒ½ï¼šç®¡ç†å¤šè½®å¯¹è¯çŠ¶æ€

å±æ€§ï¼š
- conversation_id: str
- question_id: str
- chat_history: List[Dict]  # [{"role": "user", "content": "..."}, ...]
- current_state: str  # "diagnosing" | "hinting" | "concluded"
- hint_count: int
- student_understanding: str  # "confused" | "partial" | "clear"

æ–¹æ³•1ï¼šadd_message(role, content)
- æ·»åŠ æ¶ˆæ¯åˆ°å†å²
- è‡ªåŠ¨æ›´æ–°çŠ¶æ€

æ–¹æ³•2ï¼šget_context_for_llm(max_tokens=2000)
- æˆªå–æœ€è¿‘Næ¡æ¶ˆæ¯ï¼ˆé¿å…contextè¿‡é•¿ï¼‰
- è¿”å›æ ¼å¼åŒ–çš„å†å²

æ–¹æ³•3ï¼ševaluate_student_understanding(last_response)
- ä½¿ç”¨LLMåˆ†æå­¦ç”Ÿæœ€æ–°å›å¤
- åˆ¤æ–­ç†è§£ç¨‹åº¦ï¼ˆconfused/partial/clearï¼‰
- æ›´æ–°student_understanding

æ–¹æ³•4ï¼šshould_continue_remediation()
- æ ¹æ®hint_countå’Œstudent_understandingå†³å®šæ˜¯å¦ç»§ç»­
- è¿”å›True/False
```

#### Task 3.3: æ”¹è¿›Tutor API

**æ–‡ä»¶ï¼šbackend/routers/tutor.py**ï¼ˆé‡æ„Week 1ç‰ˆæœ¬ï¼‰
```python
ç«¯ç‚¹1ï¼šPOST /api/tutor/start-remediation

è¯·æ±‚ä½“ï¼š
{
  "question_id": "q001",
  "question": {...},
  "user_choice": "A",
  "correct_choice": "C"
}

å“åº”ï¼š
{
  "conversation_id": "conv_abc123",
  "first_message": "è®©æˆ‘ä»¬åˆ†æä¸€ä¸‹ä½ çš„é€‰æ‹©...",
  "logic_gap": "å­¦ç”Ÿæ··æ·†äº†å› æœå…³ç³»"
}

åŠŸèƒ½ï¼š
1. åˆ›å»ºConversationManagerå®ä¾‹
2. è°ƒç”¨SocraticTutorAgent.diagnose_error
3. ç”Ÿæˆç¬¬ä¸€æ¡è‹æ ¼æ‹‰åº•å¼æç¤º
4. ä¿å­˜conversationçŠ¶æ€åˆ°å†…å­˜/Redis
5. è¿”å›conversation_idå’Œé¦–æ¡æ¶ˆæ¯

ç«¯ç‚¹2ï¼šPOST /api/tutor/continue

è¯·æ±‚ä½“ï¼š
{
  "conversation_id": "conv_abc123",
  "student_message": "æˆ‘è§‰å¾—Aä¹Ÿå‰Šå¼±äº†è®ºè¯å•Š"
}

å“åº”ï¼š
{
  "tutor_message": "ä½ æåˆ°Aå‰Šå¼±äº†è®ºè¯ï¼Œé‚£ä¹ˆ...",
  "student_understanding": "partial",
  "should_continue": true,
  "hint_count": 1
}

åŠŸèƒ½ï¼š
1. ä»å†…å­˜/RedisåŠ è½½conversation
2. æ·»åŠ å­¦ç”Ÿæ¶ˆæ¯
3. è¯„ä¼°ç†è§£ç¨‹åº¦
4. ç”Ÿæˆä¸‹ä¸€æ¡æç¤º
5. åˆ¤æ–­æ˜¯å¦ç»§ç»­ï¼ˆmax 3 hintsï¼‰
6. æ›´æ–°å¹¶ä¿å­˜conversation

ç«¯ç‚¹3ï¼šPOST /api/tutor/conclude

è¯·æ±‚ä½“ï¼š
{
  "conversation_id": "conv_abc123"
}

å“åº”ï¼š
{
  "final_message": "å¾ˆå¥½ï¼æ­£ç¡®ç­”æ¡ˆæ˜¯C...",
  "conversation_summary": {
    "total_turns": 3,
    "final_understanding": "clear",
    "time_spent_seconds": 120
  }
}
```

#### Task 3.4: Streamlité›†æˆæ–°Tutor

**æ–‡ä»¶ï¼šapp.py**ï¼ˆä¿®æ”¹remediationéƒ¨åˆ†ï¼‰
```python
ä¿®æ”¹ä½ç½®ï¼šphase == "remediation"çš„å¯¹è¯é€»è¾‘

æµç¨‹ï¼š
1. ç¬¬ä¸€æ¬¡ç­”é”™æ—¶ï¼Œè°ƒç”¨/api/tutor/start-remediation
   - ä¿å­˜conversation_idåˆ°session_state
   - æ˜¾ç¤ºfirst_message

2. å­¦ç”Ÿè¾“å…¥å›å¤æ—¶ï¼Œè°ƒç”¨/api/tutor/continue
   - ä¼ é€’conversation_idå’Œstudent_message
   - æ˜¾ç¤ºtutor_message
   - æ ¹æ®should_continueå†³å®šæ˜¯å¦å…è®¸ç»§ç»­è¾“å…¥

3. è¾¾åˆ°max_turnsæˆ–ç†è§£clearæ—¶ï¼Œè°ƒç”¨/api/tutor/conclude
   - æ˜¾ç¤ºfinal_message
   - æ˜¾ç¤ºè¯¦ç»†è§£æ
   - å…è®¸è¿›å…¥ä¸‹ä¸€é¢˜

ç•Œé¢æ”¹è¿›ï¼š
- æ·»åŠ "ç†è§£ç¨‹åº¦"è¿›åº¦æ¡ï¼ˆconfused â†’ partial â†’ clearï¼‰
- æ˜¾ç¤ºå½“å‰hintæ¬¡æ•°ï¼ˆ1/3, 2/3ï¼‰
- Tutoræ¶ˆæ¯ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ï¼ˆinfo vs successï¼‰
```

#### Task 3.5: Agentè¡Œä¸ºæµ‹è¯•

**æ–‡ä»¶ï¼šbackend/tests/test_tutor_agent.py**
```python
æµ‹è¯•ç”¨ä¾‹ï¼š

1. test_diagnose_error
   - è¾“å…¥é”™è¯¯ç­”æ¡ˆ
   - éªŒè¯è¿”å›logic_gapå’Œerror_type
   
2. test_socratic_hint_progression
   - æµ‹è¯•3è½®hintçš„å¼ºåº¦é€’å¢
   - ç¬¬1è½®åº”è¯¥æœ€æ¨¡ç³Š
   - ç¬¬3è½®åº”è¯¥æœ€æ˜ç¡®

3. test_understanding_evaluation
   - æä¾›ä¸åŒè´¨é‡çš„å­¦ç”Ÿå›å¤
   - éªŒè¯understandingåˆ¤æ–­å‡†ç¡®æ€§

4. test_full_remediation_flow
   - å®Œæ•´çš„3è½®å¯¹è¯æ¨¡æ‹Ÿ
   - éªŒè¯çŠ¶æ€è½¬æ¢æ­£ç¡®

5. test_conversation_manager
   - æµ‹è¯•æ¶ˆæ¯å†å²ç®¡ç†
   - æµ‹è¯•contextæˆªæ–­é€»è¾‘
```

### Week 3 éªŒæ”¶æ ‡å‡†
- [ ] LangChain Agentæ­£å¸¸å·¥ä½œ
- [ ] Tutorå¯¹è¯æœ‰æ˜ç¡®çš„çŠ¶æ€ç®¡ç†
- [ ] è‹æ ¼æ‹‰åº•æç¤ºè´¨é‡æå‡ï¼ˆæ›´æœ‰å¼•å¯¼æ€§ï¼‰
- [ ] Streamlitæ˜¾ç¤ºç†è§£ç¨‹åº¦è¿›åº¦
- [ ] è‡³å°‘4ä¸ªAgentæµ‹è¯•é€šè¿‡
- [ ] å®Œæ•´èµ°é€šä¸€ä¸ª3è½®å¯¹è¯æµç¨‹

---

## ğŸ¯ Week 4: æ•°æ®ç§‘å­¦èƒ½åŠ›ï¼ˆA/B Testing + è¯„ä¼°ä½“ç³»ï¼‰

### ç›®æ ‡
å»ºç«‹å®Œæ•´çš„å®éªŒå’Œè¯„ä¼°æ¡†æ¶ï¼Œå±•ç¤ºæ•°æ®ç§‘å­¦èƒ½åŠ›

### ä»»åŠ¡æ¸…å•

#### Task 4.1: A/B Testingæ¡†æ¶

**æ–‡ä»¶ï¼šbackend/services/ab_testing.py**ï¼ˆæ–°å»ºï¼‰
```python
ç±»ï¼šABTestService

é…ç½®å®éªŒï¼š
EXPERIMENTS = {
    "tutor_strategy": {
        "description": "æµ‹è¯•ä¸åŒTutorç­–ç•¥æ•ˆæœ",
        "variants": {
            "socratic": 0.33,      # è‹æ ¼æ‹‰åº•å¼
            "direct": 0.33,        # ç›´æ¥ç»™è§£æ
            "hybrid": 0.34         # æ··åˆæ¨¡å¼
        }
    },
    "explanation_source": {
        "description": "æµ‹è¯•RAG vs éRAGè§£æ",
        "variants": {
            "rag_enhanced": 0.5,
            "baseline": 0.5
        }
    }
}

æ–¹æ³•1ï¼šassign_variant(user_id, experiment_name)
- ä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œï¼ˆMD5ï¼‰
- ç¡®ä¿åŒä¸€user_idæ€»æ˜¯åˆ†é…åˆ°ç›¸åŒvariant
- è¿”å›variantåç§°

æ–¹æ³•2ï¼šlog_exposure(user_id, experiment, variant)
- è®°å½•ç”¨æˆ·è¢«åˆ†é…åˆ°å“ªä¸ªå®éªŒç»„
- å­˜å…¥PostgreSQLçš„experiment_logsè¡¨

æ–¹æ³•3ï¼šlog_outcome(user_id, experiment, variant, outcome_metrics)
- è®°å½•å®éªŒç»“æœæŒ‡æ ‡
- outcome_metricsç¤ºä¾‹ï¼š
  {
    "is_correct": true,
    "theta_gain": 0.15,
    "time_to_correct": 120,
    "hint_count": 2
  }

æ–¹æ³•4ï¼šis_active(experiment_name)
- æ£€æŸ¥å®éªŒæ˜¯å¦æ­£åœ¨è¿è¡Œ
- æ”¯æŒå®éªŒå¼€å…³ï¼ˆé…ç½®æ–‡ä»¶æˆ–æ•°æ®åº“ï¼‰
```

**æ–‡ä»¶ï¼šbackend/schemas/models.py**ï¼ˆæ·»åŠ è¡¨ï¼‰
```python
æ·»åŠ ExperimentLogæ¨¡å‹ï¼š

class ExperimentLog(Base):
    __tablename__ = "experiment_logs"
    
    id = Column(String, primary_key=True)  # user_id + experiment + timestamp
    user_id = Column(String, index=True)
    experiment_name = Column(String, index=True)
    variant = Column(String, index=True)
    
    # ç»“æœæŒ‡æ ‡ï¼ˆJSONå­˜å‚¨ï¼‰
    outcome_metrics = Column(JSON)
    
    # å…ƒæ•°æ®
    created_at = Column(DateTime, default=datetime.utcnow)
    question_id = Column(String)  # å…³è”çš„é¢˜ç›®
    
ç´¢å¼•ï¼š
- idx_experiment_variant (experiment_name, variant)
- idx_user_experiment (user_id, experiment_name)
```

#### Task 4.2: é›†æˆA/B Testingåˆ°API

**æ–‡ä»¶ï¼šbackend/routers/tutor.py**ï¼ˆä¿®æ”¹ï¼‰
```python
ä¿®æ”¹/api/tutor/start-remediationç«¯ç‚¹ï¼š

def start_remediation(...):
    # æ–°å¢ï¼šA/Bæµ‹è¯•åˆ†é…
    ab_service = ABTestService()
    variant = ab_service.assign_variant(user_id, "tutor_strategy")
    
    # è®°å½•exposure
    ab_service.log_exposure(user_id, "tutor_strategy", variant)
    
    # æ ¹æ®varianté€‰æ‹©ç­–ç•¥
    if variant == "socratic":
        # ä½¿ç”¨è‹æ ¼æ‹‰åº•Agent
        response = socratic_tutor.start(...)
    elif variant == "direct":
        # ç›´æ¥è¿”å›è¯¦ç»†è§£æ
        response = explanation_service.generate_direct(...)
    else:  # hybrid
        # æ··åˆæ¨¡å¼
        response = hybrid_tutor.start(...)
    
    return {"response": response, "variant": variant}
```

**æ–‡ä»¶ï¼šbackend/routers/questions.py**ï¼ˆä¿®æ”¹ï¼‰
```python
ä¿®æ”¹/api/questions/submit-answerç«¯ç‚¹ï¼š

def submit_answer(...):
    # ... åŸæœ‰é€»è¾‘ ...
    
    # æ–°å¢ï¼šè®°å½•A/Bæµ‹è¯•ç»“æœ
    if hasattr(request, 'experiment_variant'):
        ab_service.log_outcome(
            user_id=user_id,
            experiment="tutor_strategy",
            variant=request.experiment_variant,
            outcome_metrics={
                "is_correct": is_correct,
                "theta_gain": new_theta - old_theta,
                "attempt_number": attempt_number
            }
        )
```

#### Task 4.3: ç»Ÿè®¡åˆ†æè„šæœ¬

**æ–‡ä»¶ï¼šscripts/analyze_ab_tests.py**ï¼ˆæ–°å»ºï¼‰
```python
åŠŸèƒ½ï¼šåˆ†æA/Bæµ‹è¯•ç»“æœ

å‡½æ•°1ï¼šload_experiment_data(experiment_name)
- ä»PostgreSQLåŠ è½½å®éªŒæ•°æ®
- è¿”å›DataFrameï¼Œåˆ—ï¼šuser_id, variant, is_correct, theta_gainç­‰

å‡½æ•°2ï¼šcalculate_metrics_by_variant(df)
- è®¡ç®—æ¯ä¸ªvariantçš„æŒ‡æ ‡ï¼š
  - å¹³å‡æ­£ç¡®ç‡
  - å¹³å‡thetaå¢ç›Š
  - æ ·æœ¬é‡
  - æ ‡å‡†å·®

å‡½æ•°3ï¼šstatistical_significance_test(variant_a_data, variant_b_data)
- ä½¿ç”¨scipy.stats.ttest_indè¿›è¡Œtæ£€éªŒ
- è®¡ç®—p-value
- è®¡ç®—Cohen's dï¼ˆæ•ˆåº”é‡ï¼‰
- è¿”å›ï¼š
  {
    "t_statistic": 2.45,
    "p_value": 0.012,
    "cohens_d": 0.28,
    "is_significant": true
  }

å‡½æ•°4ï¼šgenerate_ab_report(experiment_name)
- ç”Ÿæˆå®Œæ•´çš„A/Bæµ‹è¯•æŠ¥å‘Š
- åŒ…å«ï¼š
  1. å®éªŒé…ç½®
  2. æ ·æœ¬é‡åˆ†å¸ƒ
  3. æŒ‡æ ‡å¯¹æ¯”è¡¨
  4. ç»Ÿè®¡æ£€éªŒç»“æœ
  5. å¯è§†åŒ–å›¾è¡¨ï¼ˆç®±çº¿å›¾ã€ç½®ä¿¡åŒºé—´ï¼‰
- ä¿å­˜ä¸ºreports/ab_test_{experiment_name}.pdf

ä¸»å‡½æ•°ï¼š
if __name__ == "__main__":
    # åŠ è½½æ•°æ®
    df = load_experiment_data("tutor_strategy")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = calculate_metrics_by_variant(df)
    print(metrics)
    
    # ç»Ÿè®¡æ£€éªŒ
    socratic_data = df[df['variant'] == 'socratic']['theta_gain']
    direct_data = df[df['variant'] == 'direct']['theta_gain']
    test_result = statistical_significance_test(socratic_data, direct_data)
    
    print(f"P-value: {test_result['p_value']:.4f}")
    print(f"Effect size (Cohen's d): {test_result['cohens_d']:.2f}")
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_ab_report("tutor_strategy")
```

#### Task 4.4: RAGè´¨é‡è¯„ä¼°ï¼ˆè¡¥å……Week 2ï¼‰

**æ–‡ä»¶ï¼šbackend/ml/llm_evaluator.py**ï¼ˆæ–°å»ºï¼‰
```python
ç±»ï¼šLLMQualityEvaluator

æ–¹æ³•1ï¼ševaluate_with_gpt4_judge(generated_explanation, reference_explanation)
- ä½¿ç”¨GPT-4ä½œä¸ºjudgeè¯„ä¼°è§£æè´¨é‡
- Promptæ¨¡æ¿ï¼š
  """
  ä½ æ˜¯GMATä¸“å®¶è¯„ä¼°å‘˜ã€‚è¯„ä¼°ä»¥ä¸‹ç”Ÿæˆçš„è§£æè´¨é‡ï¼ˆ1-5åˆ†ï¼‰ã€‚
  
  å‚è€ƒè§£æï¼ˆæ ‡å‡†ï¼‰ï¼š
  {reference}
  
  ç”Ÿæˆçš„è§£æï¼š
  {generated}
  
  è¯„åˆ†æ ‡å‡†ï¼š
  - Correctnessï¼ˆ1-5ï¼‰ï¼šæ˜¯å¦è§£é‡Šæ­£ç¡®
  - Clarityï¼ˆ1-5ï¼‰ï¼šæ˜¯å¦æ¸…æ™°æ˜“æ‡‚
  - Completenessï¼ˆ1-5ï¼‰ï¼šæ˜¯å¦å®Œæ•´
  - Pedagogical Valueï¼ˆ1-5ï¼‰ï¼šæ•™å­¦ä»·å€¼
  
  è¿”å›JSONæ ¼å¼ï¼š
  {
    "correctness": 4,
    "clarity": 5,
    "completeness": 4,
    "pedagogical_value": 4,
    "overall": 4.25,
    "justification": "è§£ææ­£ç¡®ä¸”æ¸…æ™°ï¼Œä½†..."
  }
  """
- è°ƒç”¨OpenAI APIï¼ˆgpt-4-turbo-previewï¼‰
- è§£æJSONå“åº”
- è¿”å›è¯„åˆ†å­—å…¸

æ–¹æ³•2ï¼šbatch_evaluate(test_cases)
- æ‰¹é‡è¯„ä¼°å¤šä¸ªè§£æ
- è¿”å›å¹³å‡åˆ†æ•°å’Œåˆ†å¸ƒ

æ–¹æ³•3ï¼šcalculate_inter_rater_agreement(judge1_scores, judge2_scores)
- è®¡ç®—è¯„åˆ†è€…é—´ä¸€è‡´æ€§ï¼ˆCohen's Kappaï¼‰
- ç”¨äºéªŒè¯GPT-4-as-judgeçš„å¯é æ€§
```

**æ–‡ä»¶ï¼šscripts/evaluate_llm_quality.py**ï¼ˆæ–°å»ºï¼‰
```python
åŠŸèƒ½ï¼šè¯„ä¼°LLMç”Ÿæˆçš„è§£æè´¨é‡

æ­¥éª¤ï¼š
1. ä»æ•°æ®åº“åŠ è½½20é“æœ‰æ ‡å‡†è§£æçš„é¢˜ç›®
2. ä½¿ç”¨RAGå¢å¼ºç”Ÿæˆæ–°è§£æ
3. ä½¿ç”¨baselineï¼ˆä¸ç”¨RAGï¼‰ç”Ÿæˆè§£æ
4. è°ƒç”¨LLMQualityEvaluatorè¯„ä¼°ä¸¤ä¸ªç‰ˆæœ¬
5. å¯¹æ¯”åˆ†æ•°å·®å¼‚
6. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

è¾“å‡ºç¤ºä¾‹ï¼š
=== LLM Quality Evaluation ===
Test Cases: 20

RAG-Enhanced:
  Avg Correctness: 4.3
  Avg Clarity: 4.5
  Avg Completeness: 4.1
  Avg Pedagogical Value: 4.2
  Overall: 4.28

Baseline:
  Avg Correctness: 3.8
  Avg Clarity: 3.9
  Avg Completeness: 3.7
  Avg Pedagogical Value: 3.8
  Overall: 3.80

Improvement: +12.7%
P-value: 0.003 (significant)

Report saved to reports/llm_quality_evaluation.pdf
```

#### Task 4.5: ä»ªè¡¨æ¿API

**æ–‡ä»¶ï¼šbackend/routers/analytics.py**ï¼ˆæ–°å»ºï¼‰
```python
ç«¯ç‚¹1ï¼šGET /api/analytics/ab-test-results

åŠŸèƒ½ï¼šè¿”å›A/Bæµ‹è¯•å®æ—¶ç»“æœ

å“åº”ï¼š
{
  "experiment": "tutor_strategy",
  "variants": {
    "socratic": {
      "sample_size": 150,
      "accuracy": 0.78,
      "avg_theta_gain": 0.15
    },
    "direct": {
      "sample_size": 145,
      "accuracy": 0.65,
      "avg_theta_gain": 0.10
    },
    "hybrid": {
      "sample_size": 148,
      "accuracy": 0.71,
      "avg_theta_gain": 0.12
    }
  },
  "statistical_test": {
    "comparison": "socratic vs direct",
    "p_value": 0.012,
    "effect_size": 0.28,
    "is_significant": true
  }
}

ç«¯ç‚¹2ï¼šGET /api/analytics/rag-performance

åŠŸèƒ½ï¼šè¿”å›RAGç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡

å“åº”ï¼š
{
  "retrieval_metrics": {
    "precision@5": 0.87,
    "recall@5": 0.75,
    "mrr": 0.92
  },
  "quality_metrics": {
    "avg_llm_score": 4.28,
    "improvement_vs_baseline": "+12.7%"
  },
  "system_metrics": {
    "indexed_questions": 150,
    "avg_retrieval_time_ms": 45
  }
}
```

#### Task 4.6: Streamlit Analyticsé¡µé¢

**æ–‡ä»¶ï¼šapp.py**ï¼ˆæ·»åŠ æ–°é¡µé¢ï¼‰
```python
æ–°å¢é¡µé¢ï¼š"æ•°æ®åˆ†æ"

åŠŸèƒ½ï¼š
1. A/Bæµ‹è¯•ä»ªè¡¨æ¿
   - æ˜¾ç¤ºå„variantçš„æŒ‡æ ‡å¯¹æ¯”ï¼ˆæŸ±çŠ¶å›¾ï¼‰
   - æ˜¾ç¤ºç»Ÿè®¡æ˜¾è‘—æ€§ç»“æœ
   - æ ·æœ¬é‡åˆ†å¸ƒï¼ˆé¥¼å›¾ï¼‰

2. RAGæ€§èƒ½ç›‘æ§
   - Precision/Recall/MRRè¶‹åŠ¿å›¾
   - LLMè´¨é‡è¯„åˆ†åˆ†å¸ƒï¼ˆç®±çº¿å›¾ï¼‰

3. å­¦ä¹ æ›²çº¿åˆ†æï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
   - Thetaå†å²æ›²çº¿
   - æŠ€èƒ½é›·è¾¾å›¾

å®ç°ï¼š
import plotly.graph_objects as go

# A/Bæµ‹è¯•ç»“æœ
ab_data = requests.get(f"{API_BASE_URL}/api/analytics/ab-test-results").json()

fig = go.Figure(data=[
    go.Bar(name='Socratic', x=['Accuracy', 'Theta Gain'], 
           y=[ab_data['variants']['socratic']['accuracy'], 
              ab_data['variants']['socratic']['avg_theta_gain']]),
    go.Bar(name='Direct', x=['Accuracy', 'Theta Gain'], 
           y=[ab_data['variants']['direct']['accuracy'],
              ab_data['variants']['direct']['avg_theta_gain']])
])
st.plotly_chart(fig)

# æ˜¾è‘—æ€§æ ‡æ³¨
if ab_data['statistical_test']['is_significant']:
    st.success(f"âœ… å·®å¼‚æ˜¾è‘— (p={ab_data['statistical_test']['p_value']:.4f})")
```

### Week 4 éªŒæ”¶æ ‡å‡†
- [ ] A/B Testingæ¡†æ¶è¿è¡Œ
- [ ] è‡³å°‘2ä¸ªå®éªŒæ­£åœ¨è®°å½•æ•°æ®
- [ ] åˆ†æè„šæœ¬èƒ½ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
- [ ] RAGè¯„ä¼°ï¼šPrecision@5 > 0.85
- [ ] LLMè´¨é‡è¯„ä¼°ï¼šå¹³å‡åˆ† > 4.0
- [ ] Analytics APIè¿”å›æ­£ç¡®æ•°æ®
- [ ] Streamlitæ˜¾ç¤ºæ•°æ®åˆ†æé¡µé¢

---

## ğŸ¯ Week 5: å‰ç«¯ä¼˜åŒ– + ç”¨æˆ·ä½“éªŒ

### ç›®æ ‡
æå‡å‰ç«¯äº¤äº’ä½“éªŒï¼Œå¯é€‰ï¼šReactåŸå‹æˆ–Streamlitæ·±åº¦ä¼˜åŒ–

### æ–¹æ¡ˆA: Streamlitæ·±åº¦ä¼˜åŒ–ï¼ˆæ¨èï¼Œæ—¶é—´æœ‰é™ï¼‰

#### Task 5.1: å¯¼èˆªå’Œå¸ƒå±€ä¼˜åŒ–

**æ–‡ä»¶ï¼šapp.py**ï¼ˆé‡æ„å¸ƒå±€ï¼‰
```python
ä½¿ç”¨streamlit-option-menuå®ç°ä¾§è¾¹æ å¯¼èˆªï¼š

from streamlit_option_menu import option_menu

with st.sidebar:
    page = option_menu(
        "LogicMaster AI",
        ["ç»ƒä¹ æ¨¡å¼", "æ•°æ®åˆ†æ", "å­¦ä¹ è·¯å¾„", "ç³»ç»Ÿè®¾ç½®"],
        icons=["pencil-square", "graph-up", "map", "gear"],
        default_index=0,
        styles={
            "container": {"padding": "0!important"},
            "nav-link": {"font-size": "16px", "text-align": "left"}
        }
    )

æ ¹æ®pageæ˜¾ç¤ºä¸åŒå†…å®¹ï¼š
if page == "ç»ƒä¹ æ¨¡å¼":
    # åŸæœ‰ç»ƒä¹ é€»è¾‘
elif page == "æ•°æ®åˆ†æ":
    # Week 4çš„Analyticsé¡µé¢
elif page == "å­¦ä¹ è·¯å¾„":
    # æ–°å¢ï¼šæŠ€èƒ½ä¾èµ–å›¾å’Œæ¨èè·¯å¾„
elif page == "ç³»ç»Ÿè®¾ç½®":
    # APIé…ç½®ã€å®éªŒå¼€å…³ç­‰
```

#### Task 5.2: å®æ—¶çŠ¶æ€æŒ‡ç¤ºå™¨

**æ–‡ä»¶ï¼šapp.py**ï¼ˆæ·»åŠ ï¼‰
```python
åœ¨sidebaræ·»åŠ ç³»ç»ŸçŠ¶æ€ï¼š

with st.sidebar:
    st.divider()
    st.caption("ç³»ç»ŸçŠ¶æ€")
    
    # APIå¥åº·æ£€æŸ¥
    try:
        health = requests.get(f"{API_BASE_URL}/health", timeout=2).json()
        st.success("âœ… APIåœ¨çº¿")
    except:
        st.error("âŒ APIç¦»çº¿")
    
    # æ•°æ®åº“è¿æ¥
    # RAGæœåŠ¡çŠ¶æ€
    # å½“å‰å®éªŒvariantï¼ˆå¦‚æœåœ¨A/Bæµ‹è¯•ä¸­ï¼‰
```

#### Task 5.3: é¢˜ç›®å±•ç¤ºä¼˜åŒ–

**æ–‡ä»¶ï¼šapp.py**ï¼ˆç¾åŒ–QuestionCardï¼‰
```python
ä½¿ç”¨st.containerå’Œè‡ªå®šä¹‰CSSç¾åŒ–é¢˜ç›®å±•ç¤ºï¼š

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
.question-card {
    background-color: #f8f9fa;
    padding: 20px;
    border-radius: 10px;
    border-left: 4px solid #4CAF50;
}
.choice-button {
    padding: 10px;
    margin: 5px 0;
    border-radius: 5px;
    border: 1px solid #ddd;
}
.choice-button:hover {
    background-color: #e8f4f8;
}
</style>
""", unsafe_allow_html=True)

# é¢˜ç›®å±•ç¤º
with st.container():
    st.markdown('<div class="question-card">', unsafe_allow_html=True)
    st.markdown(f"**é¢˜å‹**: {question['question_type']} | **éš¾åº¦**: {question['difficulty']}")
    st.markdown(f"**é¢˜å¹²**: {question['stimulus']}")
    st.markdown(f"**é—®é¢˜**: {question['question']}")
    st.markdown('</div>', unsafe_allow_html=True)
```

#### Task 5.4: åŠ è½½åŠ¨ç”»

**æ–‡ä»¶ï¼šapp.py**ï¼ˆæ·»åŠ loadingæ•ˆæœï¼‰
```python
åœ¨APIè°ƒç”¨æ—¶æ˜¾ç¤ºloadingï¼š

with st.spinner("ğŸ¤– AIæ­£åœ¨ç”Ÿæˆè§£æ..."):
    response = requests.post(...)
    
# æˆ–ä½¿ç”¨progress bar
progress_bar = st.progress(0)
for i in range(100):
    time.sleep(0.01)
    progress_bar.progress(i + 1)
```

#### Task 5.5: å­¦ä¹ è·¯å¾„å¯è§†åŒ–

**æ–‡ä»¶ï¼šapp.py**ï¼ˆæ–°å¢"å­¦ä¹ è·¯å¾„"é¡µé¢ï¼‰
```python
ä½¿ç”¨networkxå¯è§†åŒ–æŠ€èƒ½ä¾èµ–å›¾ï¼š

import networkx as nx
import matplotlib.pyplot as plt

# å®šä¹‰æŠ€èƒ½å›¾è°±
skill_graph = {
    "åŸºç¡€é€»è¾‘": [],
    "å› æœæ¨ç†": ["åŸºç¡€é€»è¾‘"],
    "å‡è®¾è¯†åˆ«": ["åŸºç¡€é€»è¾‘"],
    "æ›¿ä»£è§£é‡Š": ["å› æœæ¨ç†"],
    "è¯æ®å¼ºåº¦": ["å› æœæ¨ç†", "å‡è®¾è¯†åˆ«"]
}

# æ„å»ºå›¾
G = nx.DiGraph()
for skill, prereqs in skill_graph.items():
    G.add_node(skill)
    for prereq in prereqs:
        G.add_edge(prereq, skill)

# ç»˜åˆ¶
fig, ax = plt.subplots(figsize=(12, 8))
pos = nx.spring_layout(G, seed=42)
nx.draw(G, pos, with_labels=True, node_color='lightblue',
        node_size=3000, font_size=10, arrows=True, ax=ax)
st.pyplot(fig)

# æ¨èå­¦ä¹ è·¯å¾„
st.subheader("ğŸ“ æ¨èå­¦ä¹ è·¯å¾„")

# æ‰¾å‡ºæœ€è–„å¼±æŠ€èƒ½
weak_skill = find_weakest_skill(st.session_state.questions_log)

# è·å–å­¦ä¹ è·¯å¾„ï¼ˆæ‹“æ‰‘æ’åºï¼‰
path = nx.topological_sort(G)
path_to_weak = [s for s in path if s == weak_skill or s in nx.ancestors(G, weak_skill)]

st.info(f"ä½ çš„è–„å¼±æŠ€èƒ½ï¼š**{weak_skill}**")
st.markdown("å»ºè®®å­¦ä¹ é¡ºåºï¼š")
for i, skill in enumerate(path_to_weak, 1):
    st.markdown(f"{i}. {skill}")
```

### æ–¹æ¡ˆB: Reactå‰ç«¯åŸå‹ï¼ˆå¯é€‰ï¼Œå¦‚æœæœ‰æ—¶é—´ï¼‰

#### Task 5.6: Reacté¡¹ç›®æ­å»º

**åˆ›å»ºé¡¹ç›®**
```bash
cd frontend
npx create-vite@latest . --template react-ts
npm install
npm install axios @tanstack/react-query recharts
npm install -D tailwindcss postcss autoprefixer
```

#### Task 5.7: æ ¸å¿ƒç»„ä»¶

**æ–‡ä»¶ï¼šfrontend/src/components/QuestionCard.tsx**
```typescript
å®ç°é¢˜ç›®å¡ç‰‡ç»„ä»¶ï¼š

interface Props {
  question: Question;
  onSubmit: (choice: string) => void;
}

export const QuestionCard: React.FC<Props> = ({ question, onSubmit }) => {
  const [selected, setSelected] = useState<string | null>(null);

  return (
    <div className="bg-white rounded-lg shadow-lg p-6">
      {/* é¢˜å¹² */}
      <p className="mb-4">{question.stimulus}</p>
      
      {/* é—®é¢˜ */}
      <h3 className="font-semibold mb-4">{question.question}</h3>
      
      {/* é€‰é¡¹ */}
      {['A', 'B', 'C', 'D', 'E'].map(choice => (
        <button
          key={choice}
          onClick={() => setSelected(choice)}
          className={`w-full p-3 mb-2 rounded ${
            selected === choice ? 'bg-blue-100' : 'bg-gray-50'
          }`}
        >
          {choice}
        </button>
      ))}
      
      {/* æäº¤ */}
      <button
        onClick={() => selected && onSubmit(selected)}
        disabled={!selected}
        className="w-full mt-4 py-3 bg-blue-600 text-white rounded"
      >
        Submit
      </button>
    </div>
  );
};
```

**æ–‡ä»¶ï¼šfrontend/src/services/api.ts**
```typescript
å°è£…APIè°ƒç”¨ï¼š

const API_BASE = 'http://localhost:8000';

export const api = {
  getNextQuestion: async (userTheta: number) => {
    const res = await fetch(`${API_BASE}/api/questions/next`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ user_theta: userTheta })
    });
    return res.json();
  },
  
  submitAnswer: async (data: AnswerSubmission) => {
    const res = await fetch(`${API_BASE}/api/questions/submit`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(data)
    });
    return res.json();
  }
};
```

### Week 5 éªŒæ”¶æ ‡å‡†
- [ ] Streamlitå¯¼èˆªæµç•…
- [ ] ç³»ç»ŸçŠ¶æ€å®æ—¶æ˜¾ç¤º
- [ ] é¢˜ç›®å±•ç¤ºç¾è§‚
- [ ] å­¦ä¹ è·¯å¾„å¯è§†åŒ–å·¥ä½œ
- [ ] å¯é€‰ï¼šReactåŸå‹èƒ½è·‘é€šåŸºæœ¬æµç¨‹

---

## ğŸ¯ Week 6: æ–‡æ¡£ + éƒ¨ç½² + Resumeå‡†å¤‡

### ç›®æ ‡
å®Œå–„æ–‡æ¡£ï¼ŒDockeråŒ–éƒ¨ç½²ï¼Œå‡†å¤‡æ±‚èŒææ–™

### ä»»åŠ¡æ¸…å•

#### Task 6.1: å®Œå–„README

**æ–‡ä»¶ï¼šREADME.md**ï¼ˆé‡å†™ï¼‰
```markdown
ç»“æ„ï¼š
# LogicMaster AI

> AI-Native Adaptive Learning Platform for GMAT Critical Reasoning

[![Tests](https://img.shields.io/badge/tests-passing-brightgreen)]()
[![Coverage](https://img.shields.io/badge/coverage-85%25-green)]()

## ğŸ¯ Features

### Adaptive Learning Engine
- **IRT-based Ability Estimation**: 3PL model (RMSE < 0.10)
- **BKT Skill Tracking**: 10+ cognitive skills
- **Hybrid Recommendation**: IRT + BKT fusion

### AI-Powered Tutoring
- **RAG System**: Qdrant + OpenAI embeddings (Precision@5: 0.87)
- **LangChain Agent**: Multi-turn Socratic dialogue
- **Quality Assurance**: GPT-4-as-judge (avg: 4.2/5.0)

### Data Science Infrastructure
- **A/B Testing**: Consistent hashing framework
- **Statistical Analysis**: t-tests, Cohen's d, MRR
- **Real-time Analytics**: PostgreSQL + API

## ğŸ—ï¸ Architecture

[æ’å…¥æ¶æ„å›¾]

## ğŸš€ Quick Start

\`\`\`bash
# Clone repository
git clone https://github.com/yourusername/logicmaster.git
cd logicmaster

# Start services
docker-compose up -d

# Run migrations
docker-compose exec backend alembic upgrade head

# Populate data
docker-compose exec backend python scripts/populate_questions.py
docker-compose exec backend python scripts/index_to_rag.py

# Access application
# API: http://localhost:8000/docs
# UI: http://localhost:8501
\`\`\`

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| RAG Precision@5 | 87% |
| IRT Calibration RMSE | 0.10 |
| Tutor Success Rate | 78% |
| API p95 Latency | <300ms |

## ğŸ§ª Evaluation

\`\`\`bash
# Evaluate RAG system
python scripts/evaluate_rag.py

# Analyze A/B tests
python scripts/analyze_ab_tests.py

# LLM quality assessment
python scripts/evaluate_llm_quality.py
\`\`\`

## ğŸ› ï¸ Tech Stack

**Backend**: FastAPI, SQLAlchemy, LangChain  
**AI**: OpenAI API, Qdrant, DeepSeek LLM  
**Data**: PostgreSQL, Pandas, SciPy  
**Frontend**: Streamlit / React (roadmap)  
**Infra**: Docker, pytest

## ğŸ“– Documentation

- [API Documentation](docs/api.md)
- [Architecture Overview](docs/architecture.md)
- [Evaluation Methodology](docs/evaluation.md)
- [Deployment Guide](docs/deployment.md)

## ğŸ“„ License

MIT
```

#### Task 6.2: APIæ–‡æ¡£

**æ–‡ä»¶ï¼šdocs/api.md**
```markdown
# API Documentation

## Base URL
\`http://localhost:8000/api\`

## Authentication
Currently no auth required (development)

## Endpoints

### Questions

#### POST /questions/next
Get adaptive next question

**Request:**
\`\`\`json
{
  "user_theta": 0.5,
  "questions_log": [...]
}
\`\`\`

**Response:**
\`\`\`json
{
  "question_id": "q001",
  "stimulus": "...",
  "question": "...",
  "choices": ["A. ...", "B. ..."],
  "difficulty": "medium"
}
\`\`\`

[ç»§ç»­å…¶ä»–ç«¯ç‚¹...]
```

#### Task 6.3: å®Œæ•´Docker Compose

**æ–‡ä»¶ï¼šdocker-compose.yml**ï¼ˆæœ€ç»ˆç‰ˆï¼‰
```yaml
version: '3.8'

services:
  # PostgreSQL
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: logicmaster
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-dev_password}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Qdrant
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage

  # Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD:-dev_password}@postgres/logicmaster
      - QDRANT_URL=http://qdrant:6333
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_started
    volumes:
      - ./backend:/app
    restart: unless-stopped

  # Frontend (Streamlit)
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    command: streamlit run app.py --server.port 8501
    ports:
      - "8501:8501"
    environment:
      - API_BASE_URL=http://backend:8000
    depends_on:
      - backend
    volumes:
      - ./app.py:/app/app.py
    restart: unless-stopped

volumes:
  postgres_data:
  qdrant_data:
```

**æ–‡ä»¶ï¼šbackend/Dockerfile**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements-backend.txt .
RUN pip install --no-cache-dir -r requirements-backend.txt

# å¤ç”¨ç°æœ‰engineæ¨¡å—
COPY engine/ ./engine/
COPY backend/ ./

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**æ–‡ä»¶ï¼šDockerfile.streamlit**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app.py .
COPY engine/ ./engine/

CMD ["streamlit", "run", "app.py", "--server.port", "8501"]
```

#### Task 6.4: ç¯å¢ƒå˜é‡ç®¡ç†

**æ–‡ä»¶ï¼š.env.example**
```bash
# Database
POSTGRES_PASSWORD=your_secure_password

# API Keys
OPENAI_API_KEY=sk-...
DEEPSEEK_API_KEY=sk-...

# Optional
API_BASE_URL=http://localhost:8000
```

**æ–‡ä»¶ï¼š.gitignore**
```
.env
__pycache__/
*.db
*.pyc
.pytest_cache/
node_modules/
dist/
build/
```

#### Task 6.5: æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š

**æ–‡ä»¶ï¼šbackend/pytest.ini**
```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_functions = test_*
addopts = 
    --cov=backend
    --cov-report=html
    --cov-report=term
```

**è¿è¡Œæµ‹è¯•**
```bash
cd backend
pytest

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=backend --cov-report=html
# æ‰“å¼€ htmlcov/index.html æŸ¥çœ‹
```

#### Task 6.6: Resumeææ–™å‡†å¤‡

**æ–‡ä»¶ï¼šdocs/resume_bullet_points.md**
```markdown
# Resume Bullet Points for LogicMaster AI

## For AI Education Companies

â€¢ Architected AI-native GMAT training platform with FastAPI backend and PostgreSQL 
  database, implementing RESTful API design serving 50+ req/s with p95 latency <300ms

â€¢ Integrated RAG (Retrieval-Augmented Generation) system using Qdrant vector database 
  and OpenAI embeddings, achieving 87% precision@5 on explanation retrieval validated 
  through 50+ human-labeled test cases

â€¢ Developed LangChain-based Socratic tutoring agent with multi-turn dialogue management 
  and state tracking, improving student success rate to 78% within 2 attempts (baseline: 62%)

â€¢ Evaluated LLM-generated explanations using GPT-4-as-judge methodology with 5-criteria 
  rubric, establishing quality baseline (avg score: 4.2/5.0, inter-rater agreement: Îº=0.76)

## For DA/DS Positions

â€¢ Implemented A/B testing framework using consistent hashing to evaluate 3 pedagogical 
  strategies; analyzed 200+ user sessions with two-sample t-tests, identifying 15% 
  improvement in learning outcomes (p<0.01, Cohen's d=0.28)

â€¢ Calibrated 3-Parameter Logistic IRT model via maximum likelihood estimation (scipy), 
  achieving RMSE<0.10 between predicted and observed item difficulty across 150+ questions

â€¢ Built real-time analytics pipeline with PostgreSQL materialized views and Plotly 
  visualizations, tracking 10+ cognitive skills with Bayesian Knowledge Tracing

â€¢ Designed evaluation framework for retrieval systems, computing Precision@K, Recall@K, 
  and MRR metrics; automated quality assessment using GPT-4 with structured rubrics

## Technical Skills Section

**Languages**: Python (FastAPI, LangChain, SQLAlchemy, Pandas, NumPy, SciPy)  
**AI/ML**: OpenAI API, LangChain, RAG systems, Prompt Engineering  
**Databases**: PostgreSQL, Qdrant (vector DB), SQLite  
**Data Science**: Hypothesis Testing, A/B Testing, IRT, Bayesian Methods  
**Tools**: Docker, Git, pytest, Streamlit  
**Visualization**: Plotly, Matplotlib, Seaborn

## Project Link

GitHub: github.com/yourusername/logicmaster  
Demo: [deployed URL if available]
```

#### Task 6.7: æ¼”ç¤ºè„šæœ¬

**æ–‡ä»¶ï¼šdocs/demo_script.md**
```markdown
# LogicMaster AI Demo Script (5åˆ†é’Ÿ)

## Slide 1: Problem (30ç§’)
"GMATè€ƒç”Ÿéœ€è¦adaptiveç»ƒä¹ ç³»ç»Ÿï¼Œä½†ç°æœ‰å¹³å°ï¼š
- åªæœ‰é™æ€é¢˜åº“ï¼Œæ— ä¸ªæ€§åŒ–
- åé¦ˆè´¨é‡ä½ï¼Œæ— å¼•å¯¼
- ç¼ºå°‘æ•°æ®é©±åŠ¨ä¼˜åŒ–"

## Slide 2: Solution Overview (30ç§’)
"LogicMaster AIæ˜¯AI-nativeè‡ªé€‚åº”å­¦ä¹ å¹³å°ï¼š
- IRTå¼•æ“åŠ¨æ€è°ƒæ•´éš¾åº¦
- RAGå¢å¼ºçš„LLMç”Ÿæˆé«˜è´¨é‡è§£æ
- LangChain Agentæä¾›è‹æ ¼æ‹‰åº•å¼å¼•å¯¼
- A/Bæµ‹è¯•æ¡†æ¶æŒç»­ä¼˜åŒ–"

## Slide 3: Live Demo - Core Flow (2åˆ†é’Ÿ)
[æ‰“å¼€Streamlit]
1. æ˜¾ç¤ºé¢˜ç›®ï¼ˆå±•ç¤ºclean UIï¼‰
2. æ•…æ„ç­”é”™ â†’ Socratic Agentä»‹å…¥
3. å¤šè½®å¯¹è¯ â†’ æœ€ç»ˆç­”å¯¹
4. æ˜¾ç¤ºè¯¦ç»†è§£æï¼ˆRAGå¢å¼ºï¼‰

## Slide 4: Technical Deep Dive (1åˆ†é’Ÿ)
[å±•ç¤ºæ¶æ„å›¾]
- FastAPIåç«¯
- PostgreSQL + Qdrantæ··åˆå­˜å‚¨
- LangChain Agent workflow
- RAGæ£€ç´¢æµç¨‹

## Slide 5: Data Science (1åˆ†é’Ÿ)
[æ‰“å¼€Analyticsé¡µé¢]
- A/Bæµ‹è¯•ç»“æœï¼ˆp-value, effect sizeï¼‰
- RAGè¯„ä¼°æŒ‡æ ‡ï¼ˆPrecision@5: 87%)
- å­¦ä¹ æ›²çº¿å¯è§†åŒ–

## Slide 6: Impact & Next Steps (30ç§’)
"æˆæœï¼š
- TutoræˆåŠŸç‡ 62% â†’ 78%
- è§£æè´¨é‡æå‡ 12.7%
- ç»Ÿè®¡æ˜¾è‘—æ€§éªŒè¯

æœªæ¥ï¼š
- å¤šæ¨¡æ€æ”¯æŒï¼ˆå›¾è¡¨é¢˜ï¼‰
- å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–Agent
- ç§»åŠ¨ç«¯åº”ç”¨"
```

### Week 6 éªŒæ”¶æ ‡å‡†
- [ ] READMEå®Œæ•´ä¸”ä¸“ä¸š
- [ ] Docker Composeä¸€é”®å¯åŠ¨
- [ ] APIæ–‡æ¡£å®Œå–„
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] Resumeææ–™å‡†å¤‡å¥½
- [ ] æ¼”ç¤ºè„šæœ¬rehearsed

---

## ğŸ“‹ æœ€ç»ˆChecklist

### æ¶æ„å±‚é¢
- [ ] FastAPIåç«¯è¿è¡Œç¨³å®š
- [ ] PostgreSQLæ•°æ®åº“æ­£å¸¸
- [ ] Qdrantå‘é‡åº“æ­£å¸¸
- [ ] Streamlitå‰ç«¯æ­£å¸¸

### AIèƒ½åŠ›
- [ ] RAGç³»ç»Ÿå·¥ä½œï¼ˆPrecision@5 > 0.85ï¼‰
- [ ] LangChain Agentå¤šè½®å¯¹è¯æµç•…
- [ ] LLMè´¨é‡è¯„ä¼°å®Œæˆï¼ˆavg > 4.0ï¼‰

### æ•°æ®ç§‘å­¦
- [ ] A/B Testingæ¡†æ¶è¿è¡Œ
- [ ] ç»Ÿè®¡åˆ†æè„šæœ¬å®Œæˆ
- [ ] IRTæ¨¡å‹æ ¡å‡†ï¼ˆRMSE < 0.10ï¼‰
- [ ] è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ

### å·¥ç¨‹è´¨é‡
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] Dockeréƒ¨ç½²æ­£å¸¸
- [ ] APIæ–‡æ¡£å®Œæ•´
- [ ] READMEä¸“ä¸š

### æ±‚èŒææ–™
- [ ] Resume bullet pointså‡†å¤‡
- [ ] æ¼”ç¤ºè„šæœ¬å®Œæˆ
- [ ] GitHubä»“åº“æ•´æ´
- [ ] å¯é€‰ï¼šéƒ¨ç½²åˆ°äº‘ç«¯

---

## ğŸ¯ ç»™Claude Codeçš„æ‰§è¡Œæç¤º

1. **ä¸¥æ ¼å¤ç”¨ç°æœ‰ä»£ç **ï¼š
   - engine/scoring.py - ç›´æ¥å¯¼å…¥ä½¿ç”¨
   - engine/recommender.py - ç›´æ¥å¯¼å…¥ä½¿ç”¨
   - llm_service.py - åœ¨å…¶åŸºç¡€ä¸Šå¢å¼º

2. **æ¸è¿›å¼ä¿®æ”¹**ï¼š
   - å…ˆåˆ›å»ºæ–°æ–‡ä»¶ï¼Œä¸è¦æ€¥ç€åˆ é™¤æ—§ä»£ç 
   - æ¯ä¸ªWeekç»“æŸæ—¶éªŒè¯åŠŸèƒ½å®Œæ•´

3. **é”™è¯¯å¤„ç†**ï¼š
   - æ‰€æœ‰APIè°ƒç”¨éƒ½è¦try-except
   - æ•°æ®åº“æ“ä½œè¦æœ‰å›æ»š
   - LLMè°ƒç”¨å¤±è´¥è¦æœ‰fallback

4. **æµ‹è¯•é©±åŠ¨**ï¼š
   - æ¯ä¸ªæ–°åŠŸèƒ½å†™å¯¹åº”æµ‹è¯•
   - ç¡®ä¿è¦†ç›–ç‡ > 80%

5. **æ–‡æ¡£åŒæ­¥**ï¼š
   - æ¯æ¬¡ä»£ç ä¿®æ”¹åŒæ­¥æ›´æ–°README
   - APIå˜æ›´åŒæ­¥æ›´æ–°docs/api.md

Good luck! ğŸš€
